{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0BYa-zzSn7G"
      },
      "source": [
        "## Step 1: Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsnuBmTdSYlj",
        "outputId": "8c90e3d5-fa14-4183-cb60-24c4587fd559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MISTRAL_API_KEY: KxoidSRc4PqGoB59Sj5PHIG8az6OYAWc\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv() \n",
        "\n",
        "print(f\"MISTRAL_API_KEY: {os.environ.get('MISTRAL_API_KEY')}\")\n",
        "\n",
        "api_key = os.getenv(\"MISTRAL_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3HY5XhmASbrC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from mistralai import Mistral, UserMessage\n",
        "\n",
        "def mistral(user_message, model=\"mistral-small-latest\", is_json=False):\n",
        "    model = \"mistral-large-latest\"\n",
        "    client = Mistral(api_key=api_key)\n",
        "\n",
        "    messages = [\n",
        "        UserMessage(content=user_message),\n",
        "    ]\n",
        "\n",
        "    chat_response = client.chat.complete(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    return chat_response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "kairos_info= '''\n",
        "# Kairos – Business Overview\n",
        "\n",
        "## Organization\n",
        "Kairos\n",
        "\n",
        "## Business Concept\n",
        "Kairos is an AI-powered long-form video understanding and retrieval platform.\n",
        "It converts lengthy, unstructured videos into searchable, semantically organized content.\n",
        "\n",
        "Users can:\n",
        "- Upload a video\n",
        "- Ask a question in natural language\n",
        "- Retrieve the most relevant clip\n",
        "- Continue interaction via chat-based follow-up questions\n",
        "\n",
        "Kairos acts as a conversational intelligence layer over video content.\n",
        "\n",
        "---\n",
        "\n",
        "## Core Value Proposition\n",
        "\n",
        "Problem:\n",
        "Long-form videos are difficult and inefficient to search using traditional timestamp or metadata-based tools.\n",
        "\n",
        "Solution:\n",
        "Kairos enables:\n",
        "- Scene-level semantic understanding\n",
        "- Multimodal analysis (visual + speech + environmental audio)\n",
        "- Retrieval-Augmented Generation (RAG)\n",
        "- Clip-level precise retrieval\n",
        "- Context-aware Q&A\n",
        "\n",
        "Value:\n",
        "- Faster navigation\n",
        "- Improved accessibility\n",
        "- Reduced manual review time\n",
        "- Scalable video intelligence\n",
        "\n",
        "---\n",
        "\n",
        "## Target Markets\n",
        "\n",
        "Education:\n",
        "- Lecture indexing\n",
        "- Study Q&A over recordings\n",
        "\n",
        "Media & Journalism:\n",
        "- Interview clip retrieval\n",
        "- News archive search\n",
        "\n",
        "Enterprise:\n",
        "- Meeting summarization\n",
        "- Training video indexing\n",
        "- Compliance review\n",
        "\n",
        "Content Creation:\n",
        "- Highlight extraction\n",
        "- Podcast indexing\n",
        "\n",
        "---\n",
        "\n",
        "## Product Architecture (High-Level)\n",
        "\n",
        "Pipeline:\n",
        "1. Video Upload\n",
        "2. Scene Segmentation\n",
        "3. Multimodal Processing:\n",
        "   - Visual captions\n",
        "   - Object detection\n",
        "   - Speech transcription\n",
        "   - Environmental audio classification\n",
        "4. Scene-Level Description Synthesis (LLM)\n",
        "5. Embedding + Vector Index Storage\n",
        "6. RAG-Based Retrieval\n",
        "7. Chat Interface + Clip Preview\n",
        "\n",
        "Deployment:\n",
        "- Cloud-based SaaS\n",
        "- Azure infrastructure\n",
        "- Docker containerization\n",
        "- Timestamp-based streaming preview\n",
        "- On-demand clip trimming (1–3 seconds execution)\n",
        "\n",
        "---\n",
        "\n",
        "## Competitive Positioning\n",
        "\n",
        "Compared to traditional systems:\n",
        "- Supports long-form video\n",
        "- Multimodal integration\n",
        "- Scene-level granularity\n",
        "- Interactive conversational retrieval\n",
        "- Context-grounded answers\n",
        "\n",
        "Positioning:\n",
        "Scalable interactive video intelligence platform.\n",
        "\n",
        "---\n",
        "\n",
        "## Potential Business Model\n",
        "\n",
        "- SaaS subscription tiers\n",
        "- Enterprise licensing\n",
        "- API-based pricing\n",
        "- Pay-per-minute processing\n",
        "- White-label integrations\n",
        "\n",
        "---\n",
        "\n",
        "## Strategic Differentiation\n",
        "\n",
        "- Scene-based indexing\n",
        "- Multimodal fusion architecture\n",
        "- LLM-based scene synthesis\n",
        "- Retrieval-Augmented Generation\n",
        "- Conversational follow-up capability\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "Kairos is an AI-powered SaaS platform that transforms long-form video into searchable, conversationally accessible content.\n",
        "\n",
        "It enables semantic clip retrieval, interactive Q&A, and scalable multimodal understanding of complex video archives.\n",
        "\n",
        "Long-term positioning:\n",
        "- Video-native search engine\n",
        "- Enterprise video intelligence layer\n",
        "- Foundation for multimodal AI-assisted video interaction\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "general_question = \"\"\"\n",
        "You are the Kairos Customer Support Assistant.\n",
        "\n",
        "Answer based only on the general information provided below.\n",
        "\n",
        "If the answer cannot be found in the provided information, respond politely with:\n",
        "\n",
        "\"I'm unable to find that detail in the current Kairos documentation. Please contact support for further assistance.\"\n",
        "\n",
        "Do not invent information. Be clear, concise, and professional.\n",
        "\n",
        "### Kairos General Information:\n",
        "\n",
        "{kairos_info}\n",
        "\n",
        "---\n",
        "\n",
        "### User Inquiry:\n",
        "\n",
        "<<<\n",
        "{inquiry}\n",
        ">>>\n",
        "\n",
        "---\n",
        "\n",
        "### Your response as a Customer Support Assistant:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ezTMHZRJSdFq",
        "outputId": "083f3ba8-5a8f-47dd-9f64-4d101a82c78c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Kairos is an AI-powered platform designed to make long-form videos searchable and interactive. It converts lengthy, unstructured videos into organized, semantically understood content, allowing users to:\\n\\n- Upload videos\\n- Ask natural language questions\\n- Retrieve the most relevant clips\\n- Engage in follow-up conversations\\n\\nIt serves as a conversational intelligence layer for video content, enabling faster navigation, improved accessibility, and scalable video understanding.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inquiry = \"What is Kairos for?\"\n",
        "\n",
        "mistral(general_question.format(inquiry=inquiry, kairos_info=kairos_info))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMvm1-NgSs7q"
      },
      "source": [
        "## Step 2: Classification Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_htJofOdTDwH"
      },
      "outputs": [],
      "source": [
        "classification = '''\n",
        "You are a Kairos customer support intent classification system.\n",
        "Your task is to assess customer intent and categorize the customer inquiry within the `<<<>>>` markers into one of the following predefined categories:\n",
        "\n",
        "* Technical Issue\n",
        "* Feature Explanation\n",
        "* System Architecture Explanation\n",
        "* General Inquiry\n",
        "\n",
        "If the text does not fit into any of the above categories, classify it as:\n",
        "\n",
        "* General Inquiry\n",
        "\n",
        "You will respond **only** with the predefined category. Do not provide explanations or notes.\n",
        "\n",
        "###\n",
        "\n",
        "Here are some examples:\n",
        "\n",
        "**Inquiry:** My video upload keeps failing at 70%.\n",
        "**Category:** Technical Issue\n",
        "\n",
        "**Inquiry:** How do I search for a specific moment in a video?\n",
        "**Category:** Feature Explanation\n",
        "\n",
        "**Inquiry:** How does Kairos integrate ASR with the Vision-Language Model?\n",
        "**Category:** System Architecture Explanation\n",
        "\n",
        "**Inquiry:** What is Kairos?\n",
        "**Category:** General Inquiry\n",
        "\n",
        "###\n",
        "\n",
        "<<<\n",
        "**Inquiry:** {inquiry}\n",
        "\n",
        "> > >\n",
        "\n",
        "**Category:**\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9weku0dyS7hx",
        "outputId": "6389a000-bd47-48d2-c454-0fb19990dcec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'General Inquiry'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral(classification.format(inquiry=\"What is kairos about?\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjs0_rrPTWtm"
      },
      "source": [
        "## Step 3: Information Extraction Using JSON Mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "issue_extraction = \"\"\"\n",
        "You are a structured data extraction system for the Kairos Customer Support chatbot.\n",
        "\n",
        "Your task is to extract technical issue details from the customer inquiry within the `<<<>>>` markers and return the information in valid JSON format.\n",
        "\n",
        "Extract the following fields:\n",
        "\n",
        "* issue_type\n",
        "* video_length\n",
        "* video_format\n",
        "* error_message\n",
        "* stage_of_failure\n",
        "* device_or_environment\n",
        "* urgency_level\n",
        "\n",
        "Guidelines:\n",
        "\n",
        "* If a field is not mentioned, set its value to `\"Not specified\"`.\n",
        "* Do not infer details that are not clearly stated.\n",
        "* Be concise and accurate.\n",
        "* Return **only valid JSON**.\n",
        "* Do not include explanations, notes, or extra text.\n",
        "* Ensure the JSON is properly formatted.\n",
        "\n",
        "###\n",
        "\n",
        "Here are some examples:\n",
        "\n",
        "**Inquiry:** My 2-hour MP4 video fails during scene detection with a CUDA memory error.\n",
        "**Output:**\n",
        "\n",
        "{{\n",
        "  \"issue_type\": \"Processing failure\",\n",
        "  \"video_length\": \"2-hour\",\n",
        "  \"video_format\": \"MP4\",\n",
        "  \"error_message\": \"CUDA memory error\",\n",
        "  \"stage_of_failure\": \"Scene detection\",\n",
        "  \"device_or_environment\": \"GPU processing\",\n",
        "  \"urgency_level\": \"Not specified\"\n",
        "}}\n",
        "\n",
        "\n",
        "**Inquiry:** The system crashes when I upload a MOV file from my laptop.\n",
        "**Output:**\n",
        "\n",
        "{{\n",
        "  \"issue_type\": \"Upload crash\",\n",
        "  \"video_length\": \"Not specified\",\n",
        "  \"video_format\": \"MOV\",\n",
        "  \"error_message\": \"System crash\",\n",
        "  \"stage_of_failure\": \"Upload stage\",\n",
        "  \"device_or_environment\": \"Laptop\",\n",
        "  \"urgency_level\": \"Not specified\"\n",
        "}}\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "<<<\n",
        "**Inquiry:** {inquiry}\n",
        "\n",
        "> > >\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSsYs8FWTeU6",
        "outputId": "87e781fd-b368-4266-9f3b-c7a89a519115"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'```json\\n{\\n  \"issue_type\": \"Upload failure\",\\n  \"video_length\": \"5 minute\",\\n  \"video_format\": \"Not specified\",\\n  \"error_message\": \"Upload stuck\",\\n  \"stage_of_failure\": \"Upload stage\",\\n  \"device_or_environment\": \"Not specified\",\\n  \"urgency_level\": \"Not specified\"\\n}\\n```'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inquiry = \"The video is uploading for an hours now it's only 5 minute video\"\n",
        "\n",
        "mistral(issue_extraction.format(inquiry=inquiry), is_json=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9lmYn8eTmCX"
      },
      "source": [
        "## Step 4.1: Personalized Response about System architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_archi = \"\"\"\n",
        "System Architecture Explanation\n",
        "\n",
        "1) High‑Level Overview\n",
        "Kairos is a long‑form video understanding platform that transforms raw video into a structured, searchable knowledge asset. It does this by:\n",
        "\n",
        "Segmenting video into scenes.\n",
        "Extracting visual and audio evidence per scene.\n",
        "Fusing that evidence into coherent scene descriptions.\n",
        "Building a narrative summary and synopsis.\n",
        "Generating embeddings for retrieval (RAG) and enabling query‑based clip discovery.\n",
        "2) Core Components (Conceptual)\n",
        "\n",
        "Ingestion & Cataloging\n",
        "\n",
        "Source videos live in Videos/.\n",
        "A catalog file (_all_videos.json) enables batch selection and filtering (by length or explicit selection).\n",
        "Scene Segmentation Layer\n",
        "\n",
        "Uses a shot/scene detection engine to split the video into semantically consistent scenes.\n",
        "Outputs scene boundaries and timecodes.\n",
        "Optionally saves physical scene clips into an output .clips directory for inspection or downstream use.\n",
        "Visual Analysis Pipeline\n",
        "\n",
        "Frame Sampling: Selects representative frames per scene at a target resolution.\n",
        "Captioning: Generates short descriptive captions per frame using a lightweight VLM.\n",
        "Object Detection: Runs object detection on sampled frames (and/or a separate FPS stream) to produce fine‑grained object lists and spatial hints.\n",
        "Artifacts are stored under per‑video output directories (e.g., .frames, .fps, .yolo).\n",
        "Audio Analysis Pipeline\n",
        "\n",
        "Natural Sound Description: Produces semantic descriptions of non‑speech audio events.\n",
        "Speech Transcription: Produces ASR transcripts with optional VAD for clarity.\n",
        "These features align to scene time boundaries to preserve temporal context.\n",
        "Scene Evidence Fusion\n",
        "\n",
        "For each scene, all evidence streams are merged:\n",
        "Visual captions\n",
        "Object detections\n",
        "Sound descriptions\n",
        "Speech transcripts\n",
        "An LLM produces a coherent, human‑readable scene description that is more informative than any single modality.\n",
        "Narrative Construction\n",
        "\n",
        "Scene descriptions are chunked into larger blocks.\n",
        "An LLM produces multi‑scene narrative summaries, then a final synopsis.\n",
        "This provides hierarchical abstraction: scene‑level → narrative‑level → synopsis‑level.\n",
        "Retrieval (RAG) Layer\n",
        "\n",
        "Scene‑level information is embedded into a vector index.\n",
        "A conversational interface can retrieve the most relevant scenes for a user query and surface them as clip references or summaries.\n",
        "Checkpointing & Logging\n",
        "\n",
        "Each video run persists intermediate state to a checkpoint file to allow restarts without redoing costly steps.\n",
        "Logs are stored in logs/ and log_reports/ for performance tracking and reproducibility.\n",
        "3) Data Flow (End‑to‑End)\n",
        "\n",
        "Video Selection\n",
        "\n",
        "User selects one or more videos from the catalog.\n",
        "Scene Detection\n",
        "\n",
        "The video is segmented into ordered scenes; timecodes are captured.\n",
        "Per‑Scene Feature Extraction\n",
        "\n",
        "Visual frames are sampled and analyzed.\n",
        "Audio is analyzed for both speech and ambient events.\n",
        "Scene Description Generation\n",
        "\n",
        "Multimodal evidence is fused into a single scene summary.\n",
        "Narrative & Synopsis\n",
        "\n",
        "The system composes a higher‑level narrative summary and final synopsis.\n",
        "Embedding Creation\n",
        "\n",
        "Scene‑level data is embedded for retrieval.\n",
        "Querying retrieves the most relevant scenes and their evidence.\n",
        "4) Storage & Artifacts\n",
        "For each processed video, Kairos writes:\n",
        "\n",
        "Scene metadata: boundaries, timecodes, derived features.\n",
        "Intermediate outputs: frames, clips, detection results.\n",
        "Scene descriptions and narrative summaries.\n",
        "RAG embeddings for search and retrieval.\n",
        "These outputs live under _processed/ with per‑video subdirectories.\n",
        "\n",
        "5) Resilience & Reproducibility\n",
        "\n",
        "Checkpointing prevents reprocessing already‑completed stages.\n",
        "Step‑level logging ensures each stage’s runtime and outputs are tracked.\n",
        "The architecture supports incremental re‑runs (e.g., only re‑summarize scenes).\n",
        "6) Scalability Considerations\n",
        "\n",
        "Batch processing is supported through a catalog‑driven selection mechanism.\n",
        "Scene‑level parallelism is possible conceptually because scenes are independent once segmented.\n",
        "Configurable quality‑speed tradeoffs (e.g., number of frames per scene, detection FPS) allow tuning for large video sets.\n",
        "7) Extensibility\n",
        "The architecture is modular:\n",
        "\n",
        "Visual analysis can swap or add new models.\n",
        "Audio analysis can add speaker diarization or emotion.\n",
        "Fusion prompts can be updated for different reporting styles.\n",
        "Retrieval can incorporate new metadata or ranking heuristics.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_question = \"\"\"\n",
        "You are the Kairos Customer Support Assistant.\n",
        "\n",
        "Your task is to answer a user inquiry related to **System Architecture Explanation**.\n",
        "\n",
        "You must base your answer strictly and only on the system architecture information provided below.\n",
        "\n",
        "If the answer cannot be found in the provided architecture information, respond with:\n",
        "\n",
        "\"I’m unable to find that detail in the current Kairos system documentation.\"\n",
        "\n",
        "Do not invent components, models, or processes that are not explicitly mentioned.\n",
        "\n",
        "Be clear, technical, and structured.\n",
        "Use concise explanations.\n",
        "If appropriate, explain the flow of data step-by-step.\n",
        "\n",
        "### Kairos System Architecture Information:\n",
        "\n",
        "{system_archi}\n",
        "\n",
        "---\n",
        "\n",
        "### User Inquiry:\n",
        "\n",
        "<<<\n",
        "{inquiry}\n",
        "\n",
        "> > >\n",
        "\n",
        "---\n",
        "\n",
        "### Your response as a Customer Support Assistant and an expert in Kairos System Architecture:\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blMYdaxHTp2n",
        "outputId": "074b0934-8aa9-40c7-c645-a90430efb2c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the Kairos system architecture documentation, Kairos **can identify music or other non-speech audio events** in a video through its **Audio Analysis Pipeline**. Here’s how it works:\\n\\n1. **Audio Analysis Pipeline**:\\n   - The system processes audio tracks to detect and describe **natural sounds**, which explicitly includes **non-speech audio events** (e.g., music, ambient noise, sound effects).\\n   - This is handled by the **\"Natural Sound Description\"** component, which generates semantic descriptions of audio events aligned with scene time boundaries.\\n\\n2. **Output Integration**:\\n   - The detected audio events (including music) are merged with other evidence (visual, speech transcripts) during **Scene Evidence Fusion** to produce a coherent scene description.\\n   - If music is present, it will be reflected in the scene’s summary (e.g., *\"Background music plays while the speaker discusses...\"*).\\n\\n3. **Limitations**:\\n   - The architecture does not explicitly mention **music-specific features** (e.g., genre classification, BPM detection, or lyric transcription). It focuses on **semantic description** (e.g., *\"upbeat music\"*, *\"orchestral score\"*).\\n   - For speech-heavy content, music may be noted as a secondary audio layer alongside ASR transcripts.\\n\\nIf you need to confirm whether a specific video contains music, Kairos will surface this in the **scene-level audio descriptions** or the final narrative summary. For deeper music analysis (e.g., metadata extraction), additional models would need to be integrated into the modular pipeline.'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inquiry = \"Can kairos identify if there music in the video?\"\n",
        "mistral(system_question.format(inquiry=inquiry, system_archi = system_archi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.2: Personalized Response about System architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_breakdown = '''\n",
        "Feature Explanation: What Kairos Can and Can’t Do\n",
        "\n",
        "What Kairos Can Do\n",
        "* Analyze long‑form videos scene by scene\n",
        "* Automatically splits videos into meaningful scenes and processes each one.\n",
        "* Generate visual understanding\n",
        "* Captions key frames to describe what’s happening visually.\n",
        "* Detects objects to capture fine‑grained details.\n",
        "* Analyze audio content\n",
        "* Describes non‑speech sounds (e.g., ambience, effects).\n",
        "* Transcribes spoken dialogue in each scene.\n",
        "* Fuse multimodal evidence into rich scene descriptions\n",
        "* Combines visual captions, object detections, sound descriptions, and speech into a single, coherent scene report.\n",
        "* Produce narrative summaries and a final synopsis\n",
        "* Builds higher‑level summaries from scene reports and then a final synopsis for the whole video.\n",
        "* Enable retrieval‑style querying (RAG)\n",
        "* Builds embeddings so you can ask questions and retrieve the most relevant scenes.\n",
        "* Persist outputs for reuse\n",
        "* Saves scene data, summaries, and logs so you can resume or reuse results without reprocessing.\n",
        "\n",
        "What Kairos Can’t Do (Current Limitations)\n",
        "* It doesn’t “understand” beyond its models\n",
        "* It’s limited by the captioning, detection, ASR, and LLM accuracy; errors or hallucinations can appear.\n",
        "* It doesn’t guarantee perfect scene boundaries\n",
        "* Scene detection can miss subtle cuts or over‑segment fast‑moving content.\n",
        "* It doesn’t provide real‑time processing\n",
        "* Designed for offline processing of stored videos, not live streams.\n",
        "* It doesn’t fully resolve complex narrative reasoning\n",
        "* It summarizes, but it doesn’t deeply reason about plot structure, hidden motives, or nuanced themes.\n",
        "* It doesn’t output polished film‑grade annotations\n",
        "* Outputs are structured and useful, but not production‑ready cinematic annotations.\n",
        "* It doesn’t automatically handle all video types equally\n",
        "* Very static, very noisy, or visually abstract content may yield weaker results.\n",
        "* It doesn’t answer questions without prior processing\n",
        "* RAG requires that a video has already been processed and embedded.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_question = \"\"\"\n",
        "You are the Kairos Customer Support Assistant.\n",
        "\n",
        "Your task is to answer a user inquiry related to **Feature Explanation**.\n",
        "\n",
        "You must base your answer strictly and only on the feature information provided below.\n",
        "\n",
        "If the answer cannot be found in the provided feature information, respond with:\n",
        "\n",
        "\"I’m unable to find that detail in the current Kairos feature documentation.\"\n",
        "\n",
        "Do not invent features, usage steps, or functionality that are not explicitly mentioned.\n",
        "\n",
        "Be clear, technical, and structured.\n",
        "Use concise explanations.\n",
        "If appropriate, provide step-by-step instructions on how to use the feature.\n",
        "\n",
        "### Kairos Feature Information:\n",
        "\n",
        "{feature_breakdown}\n",
        "\n",
        "---\n",
        "\n",
        "### User Inquiry:\n",
        "\n",
        "<<<\n",
        "{inquiry}\n",
        ">>>\n",
        "\n",
        "---\n",
        "\n",
        "### Your response as a Customer Support Assistant and an expert in Kairos features:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, you can analyze a CCTV MP4 file with Kairos, provided it meets the following conditions:\\n\\n1. **File Type & Storage**: The video must be a stored MP4 file (not a live stream).\\n2. **Content Suitability**: Kairos performs best on content with distinguishable visuals and audio. Very static, noisy, or abstract footage may yield weaker results.\\n\\n### How to Analyze a CCTV MP4:\\n1. **Upload the Video**: Provide the stored MP4 file for offline processing.\\n2. **Automatic Processing**:\\n   - Kairos will split the video into scenes.\\n   - It will generate visual captions, detect objects, transcribe dialogue (if present), and describe non-speech sounds.\\n   - Multimodal data (visual + audio) will be fused into scene reports.\\n3. **Outputs**:\\n   - Scene-by-scene breakdowns.\\n   - Summaries and a final synopsis.\\n   - Embeddings for retrieval-style querying (RAG).\\n\\n### Limitations to Note:\\n- **Accuracy**: Results depend on the clarity of the footage (e.g., low-light or grainy videos may reduce detection accuracy).\\n- **Scene Boundaries**: Fast-moving or subtle cuts may not be perfectly segmented.\\n- **No Real-Time**: Processing is offline only.\\n\\nIf the video is already stored, you can proceed with analysis.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inquiry = \"Can i analze a CCTV mp4?\"\n",
        "mistral(feature_question.format(inquiry=inquiry, feature_breakdown = feature_breakdown))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "general_question = \"\"\"\n",
        "You are the Kairos Customer Support Assistant.\n",
        "\n",
        "Your task is to answer a user inquiry classified as **General Inquiry**.\n",
        "\n",
        "Answer based only on the general information provided below.\n",
        "\n",
        "If the answer cannot be found in the provided information, respond politely with:\n",
        "\n",
        "\"I'm unable to find that detail in the current Kairos documentation. Please contact support for further assistance.\"\n",
        "\n",
        "Do not invent information. Be clear, concise, and professional.\n",
        "\n",
        "### Kairos General Information:\n",
        "\n",
        "{general_info}\n",
        "\n",
        "---\n",
        "\n",
        "### User Inquiry:\n",
        "\n",
        "<<<\n",
        "{general_inquiry}\n",
        ">>>\n",
        "\n",
        "---\n",
        "\n",
        "### Your response as a Customer Support Assistant:\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
